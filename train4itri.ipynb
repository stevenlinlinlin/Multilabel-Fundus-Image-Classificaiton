{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LambdaLR, StepLR, OneCycleLR\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, f1_score, average_precision_score, precision_score, recall_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import KFold\n",
    "import copy\n",
    "from tqdm import tqdm \n",
    "\n",
    "# Custom imports\n",
    "from utils import *\n",
    "from dataloaders.multilabel_dataset import MultilabelDataset\n",
    "from loss_functions.focal import FocalLoss\n",
    "from loss_functions.asymmetric import AsymmetricLossOptimized\n",
    "from loss_functions.polyloss import Poly1CrossEntropyLoss, Poly1FocalLoss\n",
    "from models.resnet import ResNet50, ResNet152\n",
    "from models.densenet import DenseNet169, DenseNet161, DenseNet121\n",
    "from models.mobilenet import MobileNetV2\n",
    "from models.efficientnet import EfficientNetB3, EfficientNetB5, EfficientNetB7, EfficientNet_v2\n",
    "from models.inception import InceptionV3\n",
    "from models.vit import ViTForMultiLabelClassification, ViT\n",
    "from models.c_tran.ctran import CTranModel\n",
    "from models.utils import custom_replace\n",
    "from models.swin_transformer import SwinTransformer\n",
    "from models.convnext import ConvNeXt\n",
    "from models.mydensenet import myDenseNet1, myDenseNet2, myDenseNet3, myDenseNet4\n",
    "from models.myconvnext import ConvNeXtTransformer, ConvNeXtTransformer_concatGAP\n",
    "from models.maxvit import MaxViT\n",
    "# from models.mvit import MViT_v2\n",
    "from models.coatnet import CoAtNet\n",
    "from models.add_gcn import ADD_GCN\n",
    "from models.query2label.query2label import build_q2l\n",
    "from models.ml_decoder import create_model\n",
    "from models.tresnet import create_tresnet_model\n",
    "from models.mcar import mcar_resnet101\n",
    "\n",
    "# GPU\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.get_device_name(0))\n",
    "# print(torch.cuda.device_count())\n",
    "\n",
    "prefetch_factor = 64\n",
    "num_workers = 28\n",
    "# selected_data  = 'augmented' # 'original' or 'augmented' to evaluate the model on the original or augmented dataset\n",
    "# auc_fig_path = 'results/auc/densenet161.png'\n",
    "# results_path = 'results/densenet161_90.csv'\n",
    "# ctran_model = False # True for CTran, False for CNN\n",
    "loss_labels = 'all' # 'all' or 'unk'for all labels or only unknown labels loss respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transforms\n",
    "## Transformations adapted for the dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((384, 384)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(180),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    # transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "## Transformations adapted for the dataset testing\n",
    "transform4test = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((384, 384)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset2train(dataset_name, data_aug=None):\n",
    "    valid_labels_path = ''\n",
    "    valid_images_dir = ''\n",
    "    \n",
    "    if data_aug:\n",
    "        # print(f\"[Data Augmentation: {data_aug}]\")\n",
    "        if dataset_name == 'rfmid':\n",
    "            # RFMiD dataset\n",
    "            num_classes = 29\n",
    "            normal_class_index = 0\n",
    "            training_labels_path = f\"data/fundus/RFMiD/Training_Set/{data_aug}_new_RFMiD_Training_Labels.csv\"\n",
    "            evaluation_labels_path = 'data/fundus/RFMiD/Evaluation_Set/new_RFMiD_Validation_Labels.csv'\n",
    "            training_images_dir = 'data/fundus/RFMiD/Training_Set/Training'\n",
    "            evaluation_images_dir = 'data/fundus/RFMiD/Evaluation_Set/Validation'\n",
    "            da_training_images_dir = f\"data/fundus/RFMiD/Training_Set/{data_aug}\"\n",
    "        elif dataset_name == 'mured':\n",
    "            # MuReD dataset\n",
    "            num_classes = 20\n",
    "            normal_class_index = 1\n",
    "            training_labels_path = f\"data/fundus/MuReD/{data_aug}_train_data.csv\"\n",
    "            evaluation_labels_path = 'data/fundus/MuReD/test_data.csv'\n",
    "            training_images_dir = 'data/fundus/MuReD/images/images'\n",
    "            evaluation_images_dir = 'data/fundus/MuReD/images/images'\n",
    "            da_training_images_dir = f\"data/fundus/MuReD/images/{data_aug}\"\n",
    "        elif dataset_name == 'itri':\n",
    "            num_classes = 15\n",
    "            normal_class_index = 1\n",
    "            training_labels_path = f\"data/fundus/MuReD/{data_aug}_train_data.csv\"\n",
    "            evaluation_labels_path = 'data/fundus/MuReD/test_data.csv'\n",
    "            training_images_dir = 'data/fundus/MuReD/images/images'\n",
    "            evaluation_images_dir = 'data/fundus/MuReD/images/images'\n",
    "            da_training_images_dir = f\"data/fundus/MuReD/images/{data_aug}\"\n",
    "            valid_labels_path = ''\n",
    "            valid_images_dir = ''\n",
    "    else:\n",
    "        # print(\"[Original Data]\")\n",
    "        if dataset_name == 'rfmid':\n",
    "            # RFMiD dataset\n",
    "            num_classes = 29\n",
    "            normal_class_index = 0\n",
    "            training_labels_path = 'data/fundus/RFMiD/Training_Set/new_RFMiD_Training_Labels.csv'\n",
    "            evaluation_labels_path = 'data/fundus/RFMiD/Evaluation_Set/new_RFMiD_Validation_Labels.csv'\n",
    "            training_images_dir = 'data/fundus/RFMiD/Training_Set/Training'\n",
    "            evaluation_images_dir = 'data/fundus/RFMiD/Evaluation_Set/Validation'\n",
    "            da_training_images_dir = 'data/fundus/RFMiD/Training_Set/Training'\n",
    "        elif dataset_name == 'mured':\n",
    "            # MuReD dataset\n",
    "            num_classes = 20\n",
    "            normal_class_index = 1\n",
    "            training_labels_path = 'data/fundus/MuReD/train_data.csv'\n",
    "            evaluation_labels_path = 'data/fundus/MuReD/test_data.csv'\n",
    "            training_images_dir = 'data/fundus/MuReD/images/images'\n",
    "            evaluation_images_dir = 'data/fundus/MuReD/images/images'\n",
    "            da_training_images_dir = 'data/fundus/MuReD/images/images' # 'data/fundus/MuReD/images/xxxx' or None\n",
    "        elif dataset_name == 'itri':\n",
    "            num_classes = 15\n",
    "            normal_class_index = 1\n",
    "            training_labels_path = 'data/fundus/MuReD/train_data.csv'\n",
    "            evaluation_labels_path = 'data/fundus/MuReD/test_data.csv'\n",
    "            training_images_dir = 'data/fundus/MuReD/images/images'\n",
    "            evaluation_images_dir = 'data/fundus/MuReD/images/images'\n",
    "            da_training_images_dir = 'data/fundus/MuReD/images/images'\n",
    "            valid_labels_path = ''\n",
    "            valid_images_dir = ''\n",
    "        \n",
    "    return num_classes, training_labels_path, evaluation_labels_path, training_images_dir, evaluation_images_dir, da_training_images_dir, normal_class_index, valid_labels_path, valid_images_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "def get_dataset(num_classes, batch_size, training_labels_path, training_images_dir, da_training_images_dir, evaluation_labels_path, evaluation_images_dir, valid_labels_path, valid_images_dir):\n",
    "    train_loader = None\n",
    "    val_loader = None\n",
    "    # train dataset\n",
    "    train_dataset = MultilabelDataset(ann_dir=training_labels_path,\n",
    "                                root_dir=training_images_dir,\n",
    "                                num_labels=num_classes,\n",
    "                                transform=transform, known_labels=1, testing=False, da_root_dir=da_training_images_dir)\n",
    "    \n",
    "    if valid_labels_path:\n",
    "        valid_dataset = MultilabelDataset(ann_dir=valid_labels_path,\n",
    "                                root_dir=valid_images_dir,\n",
    "                                num_labels=num_classes,\n",
    "                                transform=transform4test, known_labels=0, testing=True)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, prefetch_factor=prefetch_factor, num_workers=num_workers)\n",
    "        val_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, prefetch_factor=prefetch_factor, num_workers=num_workers)\n",
    "\n",
    "    # test dataset\n",
    "    test_dataset = MultilabelDataset(ann_dir=evaluation_labels_path,\n",
    "                                root_dir=evaluation_images_dir,\n",
    "                                num_labels=num_classes,\n",
    "                                transform=transform4test, known_labels=0, testing=True)\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, prefetch_factor=prefetch_factor, num_workers=num_workers)\n",
    "    return train_dataset, test_dataset, test_loader, train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "def get_model(model_name, transformer_layer, num_classes):\n",
    "    if model_name == 'resnet':\n",
    "        model = ResNet152(num_classes).to(device)\n",
    "    elif model_name == 'densenet':\n",
    "        model = DenseNet121(num_classes).to(device)\n",
    "        # model = DenseNet161(num_classes).to(device)\n",
    "    elif model_name == 'mobilenet':\n",
    "        model = MobileNetV2(num_classes).to(device)\n",
    "    elif model_name == 'efficientnet':\n",
    "        model = EfficientNet_v2(num_classes).to(device)\n",
    "    elif model_name == 'inception':\n",
    "        model = InceptionV3(num_classes).to(device)\n",
    "    elif model_name == 'vit':\n",
    "        model = ViT(num_classes).to(device)\n",
    "    elif model_name == 'ctran':\n",
    "        model = CTranModel(num_labels=num_classes,use_lmt=True,pos_emb=False,layers=3,heads=4,dropout=0.1).to(device)\n",
    "    elif model_name == 'swin':\n",
    "        model = SwinTransformer(num_classes=num_classes).to(device)\n",
    "    elif model_name == 'convnext':\n",
    "        model = ConvNeXt(num_classes=num_classes).to(device)\n",
    "    elif model_name == 'mydensenet4':\n",
    "        model = myDenseNet4(num_classes).to(device)\n",
    "    elif model_name == 'myconvnext':\n",
    "        model = ConvNeXtTransformer(num_classes, num_transformer_layers=transformer_layer).to(device)\n",
    "    elif model_name == 'myconvnext_concatGAP':\n",
    "        model = ConvNeXtTransformer_concatGAP(num_classes, num_transformer_layers=transformer_layer).to(device)\n",
    "    elif model_name == 'maxvit':\n",
    "        model = MaxViT(num_classes=num_classes).to(device)\n",
    "    elif model_name == 'coatnet':\n",
    "        model = CoAtNet(num_classes=num_classes).to(device)\n",
    "    elif model_name == 'add_gcn':\n",
    "        model = ADD_GCN(num_classes=num_classes).to(device)\n",
    "    elif model_name == 'q2l':\n",
    "        model = build_q2l(num_class=num_classes).to(device)\n",
    "    elif model_name == 'ml_decoder':\n",
    "        model = create_model(num_classes=num_classes).to(device)\n",
    "    elif model_name == 'tresnet':\n",
    "        model = create_tresnet_model(num_classes=num_classes).to(device)\n",
    "    elif model_name == 'mcar':\n",
    "        model = mcar_resnet101(num_classes=num_classes,  ps='gwp', topN=4, threshold=0.5, pretrained=True).to(device)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainset to train and validation (0.8, 0.2)   \n",
    "def train(model, num_classes, train_dataset, train_loader, val_loader, learning_rate, batch_size, ctran_model=False, evaluation=False, weight_decay=False, warmup=False, loss='bce'):\n",
    "    num_epochs = 15\n",
    "    if weight_decay:\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "        # optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "    else:\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "    # Loss function\n",
    "    if model.__class__.__name__ == \"MCARResnet\":\n",
    "        criterion = nn.BCELoss()\n",
    "    elif loss == 'focal_loss':\n",
    "        print(\"[Focal Loss]\")\n",
    "        criterion = FocalLoss()\n",
    "    elif loss == 'asymmetric_loss':\n",
    "        print(\"[Asymmetric Loss]\")\n",
    "        criterion = AsymmetricLossOptimized(gamma_neg=1, gamma_pos=0)\n",
    "        # criterion = AsymmetricLossOptimized()\n",
    "    elif loss == 'bce':\n",
    "        print(\"[BCE Loss]\")\n",
    "        criterion = nn.BCEWithLogitsLoss(reduction='sum')\n",
    "    elif loss == 'poly_ce':\n",
    "        print(\"[Poly Loss (bce)]\")\n",
    "        criterion = Poly1CrossEntropyLoss(num_classes, reduction='sum')\n",
    "    elif loss == 'poly_focal':\n",
    "        print(\"[Poly Loss (Focal)]\")\n",
    "        criterion = Poly1FocalLoss(num_classes, reduction='sum')\n",
    "    \n",
    "    if warmup:\n",
    "        num_epochs += 5\n",
    "        warmup_scheduler = LambdaLR(optimizer, lr_lambda=linear_warmup)\n",
    "        \n",
    "    step_scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    # step_scheduler = OneCycleLR(optimizer, max_lr=learning_rate, steps_per_epoch=10, epochs=num_epochs, div_factor=10, final_div_factor=100)\n",
    "    \n",
    "    \n",
    "    if val_loader is None:\n",
    "        if evaluation:\n",
    "            # torch.manual_seed(13)\n",
    "            total_size = len(train_dataset)\n",
    "            val_size = int(total_size * 0.2)\n",
    "            train_size = total_size - val_size\n",
    "            train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "            \n",
    "            # train_label_counts = count_labels(train_dataset, num_classes)\n",
    "            # val_label_counts = count_labels(val_dataset, num_classes)\n",
    "            # sorted_train_label_counts = dict(sorted(train_label_counts.items()))\n",
    "            # sorted_val_label_counts = dict(sorted(val_label_counts.items()))\n",
    "            # print(\"Train Label Counts:     \", sorted_train_label_counts)\n",
    "            # print(\"Validation Label Counts:\", sorted_val_label_counts)\n",
    "            \n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, prefetch_factor=prefetch_factor, num_workers=num_workers)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, prefetch_factor=prefetch_factor, num_workers=num_workers)\n",
    "        else:\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, prefetch_factor=prefetch_factor, num_workers=num_workers)\n",
    "    else:\n",
    "        evaluation = True\n",
    "\n",
    "    best_train_loss = float('inf')\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    for epoch in tqdm(range(num_epochs), desc='Epoch'):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            if ctran_model:\n",
    "                labels = batch['labels'].float()\n",
    "                images = batch['image'].float()\n",
    "                mask = batch['mask'].float()\n",
    "                unk_mask = custom_replace(mask,1,0,0)\n",
    "                mask_in = mask.clone()\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs,_,_ = model(images.to(device),mask_in.to(device))\n",
    "                \n",
    "                loss =  F.binary_cross_entropy_with_logits(outputs.view(labels.size(0),-1),labels.cuda(),reduction='none')\n",
    "                if loss_labels == 'unk': \n",
    "                    # only use unknown labels for loss\n",
    "                    loss_out = (unk_mask.cuda()*loss).sum()\n",
    "                else: \n",
    "                    # use all labels for loss\n",
    "                    loss_out = loss.sum()\n",
    "                    \n",
    "            else:\n",
    "                inputs, labels = batch['image'].to(device), batch['labels'].to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                # print(outputs.shape, labels.shape)\n",
    "                # loss_out = F.binary_cross_entropy_with_logits(outputs, labels, reduction='none').sum() # sigmoid + BCELoss\n",
    "                if model.__class__.__name__ == \"MCARResnet\":\n",
    "                    loss_out = criterion(outputs[0], labels) + criterion(outputs[1], labels)\n",
    "                else:\n",
    "                    loss_out = criterion(outputs, labels)\n",
    "            \n",
    "            train_loss += loss_out.item()\n",
    "            loss_out.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        # scheduler.step()\n",
    "        if epoch < 5:\n",
    "            if warmup:\n",
    "                # print(warmup_scheduler.get_last_lr())\n",
    "                warmup_scheduler.step()\n",
    "            else:\n",
    "                step_scheduler.step()\n",
    "                # print(step_scheduler.get_last_lr())\n",
    "        else:\n",
    "            step_scheduler.step()\n",
    "            # print(step_scheduler.get_last_lr())\n",
    "\n",
    "        if not evaluation:\n",
    "            current_train_loss = train_loss / len(train_loader)\n",
    "            if current_train_loss < best_train_loss:\n",
    "                best_train_loss = current_train_loss\n",
    "                best_model_state = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss/len(train_loader):.6f}')\n",
    "            continue\n",
    "    \n",
    "        # Evaluate the model on the validation set\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        # correct_predictions = 0\n",
    "        # total_jaccard_index = 0.0\n",
    "        # total_samples = 0\n",
    "        auc_scores = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            all_preds = []\n",
    "            all_labels = []\n",
    "            all_preds_4 = []\n",
    "            all_labels_4 = []\n",
    "            all_preds_5 = []\n",
    "            all_labels_5 = []\n",
    "            for batch in val_loader:\n",
    "                if ctran_model:\n",
    "                    labels = batch['labels'].float()\n",
    "                    images = batch['image'].float()\n",
    "                    mask = batch['mask'].float()\n",
    "                    mask_in = mask.clone()\n",
    "                    unk_mask = custom_replace(mask,1,0,0)\n",
    "                    \n",
    "                    outputs,int_pred,attns = model(images.to(device),mask_in.to(device))\n",
    "                    \n",
    "                    loss = F.binary_cross_entropy_with_logits(outputs.view(labels.size(0),-1),labels.cuda(), reduction='none')\n",
    "                    loss_out = (unk_mask.cuda()*loss).sum()\n",
    "                    outputs = F.sigmoid(outputs)\n",
    "                else:\n",
    "                    inputs, labels = batch['image'].to(device), batch['labels'].to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    # loss_out = F.binary_cross_entropy_with_logits(outputs, labels, reduction='none').sum()\n",
    "                    if model.__class__.__name__ == \"MCARResnet\":\n",
    "                        loss_out = criterion(outputs[0], labels) + criterion(outputs[1], labels)\n",
    "                        outputs  = torch.max(outputs[0], outputs[1])\n",
    "                    else:\n",
    "                        loss_out = criterion(outputs, labels)\n",
    "                        outputs = F.sigmoid(outputs)\n",
    "                    \n",
    "                val_loss += loss_out.item()\n",
    "\n",
    "                # Calculate accuracy\n",
    "                ## method 1. Strictly Accuracy\n",
    "                # predicted_labels = (outputs > 0.5).float()\n",
    "                # correct_predictions += (predicted_labels == labels).all(dim=1).sum().item()\n",
    "                # total_samples += labels.size(0)\n",
    "                \n",
    "                ## method 2. Jaccard Accuracy\n",
    "                # predicted = (outputs > 0.5).bool()\n",
    "                # labels_bool = labels.bool()\n",
    "                # intersection = (predicted & labels_bool).float().sum(dim=1)\n",
    "                # union = (predicted | labels_bool).float().sum(dim=1)\n",
    "                # jaccard_index_per_example = intersection / union\n",
    "                # jaccard_index_per_example[union == 0] = 1.0\n",
    "                # total_jaccard_index += jaccard_index_per_example.sum().item()\n",
    "                # total_samples += labels.size(0)\n",
    "                \n",
    "                ## method 3. AUC\n",
    "                outputs_np = outputs.cpu().numpy()\n",
    "                # outputs_np = outputs.cpu().numpy()\n",
    "                labels_np = labels.cpu().numpy()\n",
    "                all_preds.extend(outputs_np)\n",
    "                all_labels.extend(labels_np)\n",
    "                \n",
    "                ## method 4. mAP\n",
    "                all_preds_4.append(outputs.cpu())\n",
    "                # all_preds_4.append(outputs.cpu())\n",
    "                all_labels_4.append(labels.cpu())\n",
    "                \n",
    "                ## method 5. F1 Score\n",
    "                predicted = outputs.cpu() > 0.5\n",
    "                # predicted = outputs.cpu() > 0.5\n",
    "                all_preds_5.append(predicted.numpy())\n",
    "                all_labels_5.append(labels.cpu().numpy())\n",
    "\n",
    "        current_val_loss = val_loss / len(val_loader)\n",
    "        if current_val_loss < best_val_loss:\n",
    "            best_val_loss = current_val_loss\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        # if rfmid_ori:\n",
    "        #     print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss/len(train_loader):.6f}, Validation Loss: {val_loss/len(val_loader):.6f}')\n",
    "        #     continue\n",
    "        \n",
    "        ## method 1.\n",
    "        # accuracy = correct_predictions / total_samples\n",
    "        ## method 2.\n",
    "        # accuracy = total_jaccard_index / total_samples\n",
    "        ## method 3.\n",
    "        for i in range(labels_np.shape[1]):\n",
    "                label_specific_auc = roc_auc_score([label[i] for label in all_labels], [pred[i] for pred in all_preds])\n",
    "                auc_scores.append(label_specific_auc)\n",
    "        average_auc = sum(auc_scores) / len(auc_scores)\n",
    "        ## method 4. mAP\n",
    "        all_preds_4 = torch.cat(all_preds_4).numpy()\n",
    "        all_labels_4 = torch.cat(all_labels_4).numpy()\n",
    "        mAP = 0\n",
    "        for i in range(all_labels_4.shape[1]):\n",
    "            AP = average_precision_score(all_labels_4[:, i], all_preds_4[:, i])\n",
    "            mAP += AP\n",
    "\n",
    "        mAP /= all_labels_4.shape[1]\n",
    "        ## method 5. F1 Score\n",
    "        all_preds_5 = np.vstack(all_preds_5)\n",
    "        all_labels_5 = np.vstack(all_labels_5)\n",
    "        f1_macro = f1_score(all_labels_5, all_preds_5, average='macro')\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss/len(train_loader):.6f}, Validation Loss: {val_loss/len(val_loader):.6f}, F1_macro: {f1_macro:.3f}, mAP: {mAP:.3f}, Average AUC: {average_auc:.3f}')\n",
    "    return best_model_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "def evaluate(model, best_model_state, test_loader, results_path, evaluation_labels_path, dataset_name, normal_index=1, ctran_model=False, best_model=False):\n",
    "    if best_model:\n",
    "        print(\"~~~~~~~~~~ Best model evaluation ~~~~~~~~~~\")\n",
    "        model.load_state_dict(best_model_state)\n",
    "        \n",
    "    model.eval()\n",
    "    # correct_predictions = 0\n",
    "    # total_jaccard_index = 0.0\n",
    "    # total_samples = 0\n",
    "    auc_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        all_preds_4 = []\n",
    "        all_labels_4 = []\n",
    "        all_preds_5 = []\n",
    "        all_labels_5 = []\n",
    "        \n",
    "        for batch in test_loader:\n",
    "            if ctran_model:\n",
    "                labels = batch['labels'].float()\n",
    "                images = batch['image'].float()\n",
    "                mask = batch['mask'].float()\n",
    "                mask_in = mask.clone()\n",
    "                unk_mask = custom_replace(mask,1,0,0)\n",
    "                \n",
    "                outputs,int_pred,attns = model(images.to(device),mask_in.to(device))\n",
    "            else:\n",
    "                inputs, labels = batch['image'].to(device), batch['labels'].to(device)\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "            if model.__class__.__name__ == \"MCARResnet\":\n",
    "                outputs  = torch.max(outputs[0], outputs[1])\n",
    "            else:\n",
    "                outputs = F.sigmoid(outputs)\n",
    "                \n",
    "            # Calculate accuracy\n",
    "            ## method 1. Strictly Accuracy\n",
    "            # predicted_labels = (outputs > 0.5).float()\n",
    "            # correct_predictions += (predicted_labels == labels).all(dim=1).sum().item()\n",
    "            # total_samples += labels.size(0)\n",
    "            \n",
    "            ## method 2. Jaccard Accuracy\n",
    "            # predicted = (outputs > 0.5).bool()\n",
    "            # labels_bool = labels.bool()\n",
    "            # intersection = (predicted & labels_bool).float().sum(dim=1)\n",
    "            # union = (predicted | labels_bool).float().sum(dim=1)\n",
    "            # jaccard_index_per_example = intersection / union\n",
    "            # jaccard_index_per_example[union == 0] = 1.0\n",
    "            # total_jaccard_index += jaccard_index_per_example.sum().item()\n",
    "            # total_samples += labels.size(0)\n",
    "            \n",
    "            ## method 3. AUC\n",
    "            outputs_np = outputs.cpu().numpy()\n",
    "            # outputs_np = outputs.cpu().numpy()\n",
    "            labels_np = labels.cpu().numpy()\n",
    "            all_preds.extend(outputs_np)\n",
    "            all_labels.extend(labels_np)\n",
    "            \n",
    "            ## method 4. mAP\n",
    "            all_preds_4.append(outputs.cpu())\n",
    "            # all_preds_4.append(outputs.cpu())\n",
    "            all_labels_4.append(labels.cpu())\n",
    "            \n",
    "            ## method 5. F1 Score\n",
    "            predicted = outputs.cpu() > 0.5\n",
    "            # predicted = outputs.cpu() > 0.5\n",
    "            all_preds_5.append(predicted.numpy())\n",
    "            all_labels_5.append(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "    ## method 1.\n",
    "    # accuracy = correct_predictions / total_samples\n",
    "    ## method 2.\n",
    "    # accuracy = total_jaccard_index / total_samples\n",
    "    ## method 3.\n",
    "    # print(len(all_preds), all_preds[0].shape, labels_np.shape)\n",
    "    for i in range(labels_np.shape[1]):\n",
    "        # print(len(all_labels))\n",
    "        # print([label[i] for label in all_labels], [pred[i] for pred in all_preds])\n",
    "        label_specific_auc = roc_auc_score([label[i] for label in all_labels], [pred[i] for pred in all_preds])\n",
    "        auc_scores.append(label_specific_auc)\n",
    "        \n",
    "        # Precision and Recall\n",
    "        label_specific_precision = precision_score([label[i] for label in all_labels], [pred[i] > 0.5 for pred in all_preds], zero_division=0)\n",
    "        label_specific_recall = recall_score([label[i] for label in all_labels], [pred[i] > 0.5 for pred in all_preds], zero_division=0)\n",
    "        precision_scores.append(label_specific_precision)\n",
    "        recall_scores.append(label_specific_recall)\n",
    "        \n",
    "    average_auc = sum(auc_scores) / len(auc_scores)\n",
    "    average_precision = sum(precision_scores) / len(precision_scores)\n",
    "    average_recall = sum(recall_scores) / len(recall_scores)\n",
    "    ## method 4. mAP\n",
    "    all_preds_4 = torch.cat(all_preds_4).numpy()\n",
    "    all_labels_4 = torch.cat(all_labels_4).numpy()\n",
    "    mAP = 0\n",
    "    mAP_per_label = []\n",
    "    for i in range(all_labels_4.shape[1]):\n",
    "        AP = average_precision_score(all_labels_4[:, i], all_preds_4[:, i])\n",
    "        mAP_per_label.append(AP)\n",
    "        mAP += AP\n",
    "\n",
    "    mAP /= all_labels_4.shape[1]\n",
    "    ## method 5. F1 Score\n",
    "    all_preds_5 = np.vstack(all_preds_5)\n",
    "    all_labels_5 = np.vstack(all_labels_5)\n",
    "    f1_macro = f1_score(all_labels_5, all_preds_5, average='macro')\n",
    "    f1_list = list(f1_score(all_labels_5, all_preds_5, average=None))\n",
    "    ## method 6. Overall precision and recall and F1\n",
    "    overall_precision, overall_recall, overall_f1, _ = precision_recall_fscore_support(all_labels_5.ravel(), all_preds_5.ravel(), average='binary')\n",
    "    overall_precision = round(overall_precision, 3)\n",
    "    overall_recall = round(overall_recall, 3)\n",
    "    overall_f1 = round(overall_f1, 3)\n",
    "    # print(overall_precision, overall_recall, overall_f1)\n",
    "    \n",
    "    if dataset_name == 'rfmid':\n",
    "        os.makedirs('results/rfmid', exist_ok=True)\n",
    "    elif dataset_name == 'mured':\n",
    "        os.makedirs('results/mured', exist_ok=True)\n",
    "    avg_results = result2csv(results_path, evaluation_labels_path, precision_scores, recall_scores, f1_list, mAP_per_label, auc_scores, best_model)\n",
    "    # print(f'Evaluation - Average Precision: {average_precision:.3f}, Average Recall: {average_recall:.3f}, F1_macro: {f1_macro:.3f}, mAP: {mAP:.3f}, Average AUC: {average_auc:.3f}, ML Scores: {(mAP + average_auc) / 2:.3f}')\n",
    "    \n",
    "    normal_auc = auc_scores.pop(normal_index)\n",
    "    average_auc = sum(auc_scores) / len(auc_scores)\n",
    "    normal_f1 = f1_list.pop(normal_index)\n",
    "    f1_macro = sum(f1_list) / len(f1_list)\n",
    "    mAP_per_label.pop(normal_index)\n",
    "    mAP = sum(mAP_per_label) / len(mAP_per_label)\n",
    "    ML_score = (mAP + average_auc) / 2\n",
    "    eval_results = [f1_macro, mAP, average_auc, ML_score, normal_f1, normal_auc, (ML_score + normal_auc) / 2]\n",
    "    eval_results = [str(round(result, 3)) for result in eval_results]\n",
    "    results2allcsv(results_path, eval_results, avg_results, dataset_name, overall_precision, overall_recall, overall_f1, best_model)\n",
    "    print(f'===== Evaluation results =====')\n",
    "    print(f'OP: {overall_precision}, OR: {overall_recall}, OF1: {overall_f1}, CP: {avg_results[0]}, CR: {avg_results[1]}, CF1: {avg_results[2]}, mAP: {avg_results[3]}, Average AUC: {avg_results[4]}')\n",
    "    print(f'ML_F1: {f1_macro:.3f}, ML_mAP: {mAP:.3f}, ML_AUC: {average_auc:.3f}, ML_Score: {ML_score:.3f}, Bin_F1: {normal_f1:.3f}, Bin_AUC: {normal_auc:.3f}, Model_Score: {(ML_score + normal_auc) / 2:.3f}')\n",
    "    # plot_auc_curve(all_preds, all_labels, evaluation_labels_path, auc_fig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(args):\n",
    "    num_classes, training_labels_path, evaluation_labels_path, training_images_dir, evaluation_images_dir, da_training_images_dir, normal_class_index, valid_labels_path, valid_images_dir = dataset2train(args.dataset, args.data_aug)\n",
    "    train_dataset, test_dataset, test_loader, train_loader, val_loader = get_dataset(num_classes=num_classes, batch_size=args.batch_size, training_labels_path=training_labels_path, training_images_dir=training_images_dir, da_training_images_dir=da_training_images_dir, evaluation_labels_path=evaluation_labels_path, evaluation_images_dir=evaluation_images_dir, valid_labels_path=valid_labels_path, valid_images_dir=valid_images_dir)\n",
    "    model = get_model(args.model, args.transformer_layer, num_classes)\n",
    "    print(f\"===== Model: {model.__class__.__name__} =====\")\n",
    "    print(f\"<training_labels_path: {training_labels_path}>\")\n",
    "    print(\"******************** Training   ********************\")\n",
    "    if args.plm:\n",
    "        best_model_state = train_plm(model, train_dataset, args.lr, ctran_model=args.ctran_model, warmup=args.warmup, evaluation=args.val, num_classes=num_classes, batch_size=args.batch_size, prefetch_factor=prefetch_factor, num_workers=num_workers, device=device, loss=args.loss)\n",
    "    else:\n",
    "        best_model_state = train(model, num_classes, train_dataset, train_loader, val_loader, args.lr, batch_size=args.batch_size, ctran_model=args.ctran_model, evaluation=args.val, weight_decay=args.weight_decay, warmup=args.warmup, loss=args.loss)\n",
    "    # best_model_state = train_kfold(model, train_dataset, args.lr, ctran_model=args.ctran_model)\n",
    "    print(\"******************** Testing ********************\")\n",
    "    evaluate(model, best_model_state, test_loader, args.save_results_path, evaluation_labels_path, args.dataset, normal_index=normal_class_index, ctran_model=args.ctran_model)\n",
    "    evaluate(model, best_model_state, test_loader, args.save_results_path, evaluation_labels_path, args.dataset, normal_index=normal_class_index, ctran_model=args.ctran_model, best_model =True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Model: DenseNet121 =====\n",
      "<training_labels_path: data/fundus/MuReD/train_data.csv>\n",
      "******************** Training   ********************\n",
      "[BCE Loss]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   7%|▋         | 1/15 [00:18<04:13, 18.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Training Loss: 97.784015, Validation Loss: 60.884679, F1_macro: 0.056, mAP: 0.314, Average AUC: 0.824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  13%|█▎        | 2/15 [00:33<03:36, 16.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15, Training Loss: 54.691715, Validation Loss: 51.524996, F1_macro: 0.109, mAP: 0.406, Average AUC: 0.870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 3/15 [00:49<03:17, 16.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15, Training Loss: 49.368710, Validation Loss: 47.681030, F1_macro: 0.157, mAP: 0.445, Average AUC: 0.902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  27%|██▋       | 4/15 [01:05<02:59, 16.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15, Training Loss: 44.766155, Validation Loss: 47.042699, F1_macro: 0.196, mAP: 0.448, Average AUC: 0.892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  33%|███▎      | 5/15 [01:21<02:41, 16.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15, Training Loss: 43.160092, Validation Loss: 43.386562, F1_macro: 0.261, mAP: 0.476, Average AUC: 0.914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 6/15 [01:37<02:24, 16.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15, Training Loss: 40.648625, Validation Loss: 41.829372, F1_macro: 0.333, mAP: 0.502, Average AUC: 0.914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  47%|████▋     | 7/15 [01:53<02:08, 16.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15, Training Loss: 38.866742, Validation Loss: 40.620421, F1_macro: 0.331, mAP: 0.534, Average AUC: 0.922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  53%|█████▎    | 8/15 [02:09<01:52, 16.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15, Training Loss: 37.404167, Validation Loss: 38.877610, F1_macro: 0.349, mAP: 0.583, Average AUC: 0.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 9/15 [02:26<01:36, 16.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15, Training Loss: 35.725660, Validation Loss: 38.588947, F1_macro: 0.372, mAP: 0.580, Average AUC: 0.930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  67%|██████▋   | 10/15 [02:42<01:20, 16.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15, Training Loss: 34.715177, Validation Loss: 36.617937, F1_macro: 0.407, mAP: 0.611, Average AUC: 0.934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  73%|███████▎  | 11/15 [02:57<01:04, 16.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15, Training Loss: 32.515981, Validation Loss: 35.100676, F1_macro: 0.458, mAP: 0.635, Average AUC: 0.941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 12/15 [03:13<00:48, 16.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15, Training Loss: 30.575053, Validation Loss: 34.881088, F1_macro: 0.418, mAP: 0.650, Average AUC: 0.942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  87%|████████▋ | 13/15 [03:30<00:32, 16.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15, Training Loss: 30.374873, Validation Loss: 35.259285, F1_macro: 0.429, mAP: 0.618, Average AUC: 0.945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  93%|█████████▎| 14/15 [03:46<00:16, 16.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15, Training Loss: 30.354422, Validation Loss: 35.680151, F1_macro: 0.425, mAP: 0.614, Average AUC: 0.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 15/15 [04:02<00:00, 16.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15, Training Loss: 29.275080, Validation Loss: 33.788680, F1_macro: 0.445, mAP: 0.646, Average AUC: 0.938\n",
      "******************** Testing ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Writing each label results to results/mured/densenet.csv]\n",
      "[Evaluation all results has been written to *results/all_models_results_mured.csv*]\n",
      "===== Evaluation results =====\n",
      "OP: 0.805, OR: 0.58, OF1: 0.674, CP: 0.575, CR: 0.409, CF1: 0.467, mAP: 0.622, Average AUC: 0.944\n",
      "ML_F1: 0.448, ML_mAP: 0.607, ML_AUC: 0.943, ML_Score: 0.775, Bin_F1: 0.827, Bin_AUC: 0.971, Model_Score: 0.873\n",
      "\n",
      "~~~~~~~~~~ Best model evaluation ~~~~~~~~~~\n",
      "[Writing each label results to results/mured/densenet_best.csv]\n",
      "[Evaluation all results has been written to *results/all_models_results_mured_best.csv*]\n",
      "===== Evaluation results =====\n",
      "OP: 0.805, OR: 0.58, OF1: 0.674, CP: 0.575, CR: 0.409, CF1: 0.467, mAP: 0.622, Average AUC: 0.944\n",
      "ML_F1: 0.448, ML_mAP: 0.607, ML_AUC: 0.943, ML_Score: 0.775, Bin_F1: 0.827, Bin_AUC: 0.971, Model_Score: 0.873\n",
      "===== Model: CTranModel =====\n",
      "<training_labels_path: data/fundus/MuReD/train_data.csv>\n",
      "******************** Training   ********************\n",
      "[BCE Loss]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/15 [00:08<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 9.77 GiB of which 38.69 MiB is free. Including non-PyTorch memory, this process has 9.66 GiB memory in use. Of the allocated memory 7.73 GiB is allocated by PyTorch, and 448.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m params \u001b[38;5;129;01min\u001b[39;00m parameter_sets:\n\u001b[1;32m     28\u001b[0m     args \u001b[38;5;241m=\u001b[39m Args(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m---> 29\u001b[0m     \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m, in \u001b[0;36mrun_model\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m      9\u001b[0m     best_model_state \u001b[38;5;241m=\u001b[39m train_plm(model, train_dataset, args\u001b[38;5;241m.\u001b[39mlr, ctran_model\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mctran_model, warmup\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mwarmup, evaluation\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mval, num_classes\u001b[38;5;241m=\u001b[39mnum_classes, batch_size\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch_size, prefetch_factor\u001b[38;5;241m=\u001b[39mprefetch_factor, num_workers\u001b[38;5;241m=\u001b[39mnum_workers, device\u001b[38;5;241m=\u001b[39mdevice, loss\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mloss)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 11\u001b[0m     best_model_state \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctran_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctran_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarmup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarmup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# best_model_state = train_kfold(model, train_dataset, args.lr, ctran_model=args.ctran_model)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m******************** Testing ********************\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 98\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dataset, train_loader, val_loader, learning_rate, batch_size, ctran_model, evaluation, weight_decay, warmup, loss)\u001b[0m\n\u001b[1;32m     95\u001b[0m             loss_out \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     97\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_out\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 98\u001b[0m     \u001b[43mloss_out\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# scheduler.step()\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/multilabel/lib/python3.9/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/multilabel/lib/python3.9/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 9.77 GiB of which 38.69 MiB is free. Including non-PyTorch memory, this process has 9.66 GiB memory in use. Of the allocated memory 7.73 GiB is allocated by PyTorch, and 448.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    def __init__(self, model='myconvnext_concatGAP', save_results_path='results/myconvnext_concatGAP.csv', ctran_model=False,\n",
    "                 lr=0.0001, batch_size=16, val=True, transformer_layer=2, dataset='mured', weight_decay=True, warmup=False,\n",
    "                 data_aug=None, plm=False, loss='bce'):\n",
    "        self.model = model\n",
    "        self.save_results_path = save_results_path\n",
    "        self.ctran_model = ctran_model\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.val = val\n",
    "        self.transformer_layer = transformer_layer\n",
    "        self.dataset = dataset\n",
    "        self.weight_decay = weight_decay\n",
    "        self.warmup = warmup\n",
    "        self.data_aug = data_aug\n",
    "        self.plm = plm\n",
    "        self.loss = loss\n",
    "\n",
    "parameter_sets = [\n",
    "    # {'model': 'densenet', 'save_results_path': 'results/mured/densenet.csv', 'dataset': 'mured'},\n",
    "    {'model': 'swin', 'save_results_path': 'results/mured/swinV2-B.csv', 'dataset': 'mured'},\n",
    "    {'model': 'convnext', 'save_results_path': 'results/mured/convnextV2-L.csv', 'dataset': 'mured'},\n",
    "    {'model': 'myconvnext', 'save_results_path': 'results/mured/myconvnext_1layer.csv', 'dataset': 'mured', 'transformer_layer': 1},\n",
    "    {'model': 'myconvnext', 'save_results_path': 'results/mured/myconvnext_2layer.csv', 'dataset': 'mured', 'transformer_layer': 2},\n",
    "    {'model': 'myconvnext', 'save_results_path': 'results/mured/myconvnext_3layer.csv', 'dataset': 'mured', 'transformer_layer': 3},\n",
    "    {'model': 'myconvnext_concatGAP', 'save_results_path': 'results/mured/myconvnext_1layer_concatGAP.csv', 'dataset': 'mured', 'transformer_layer': 1},\n",
    "    {'model': 'myconvnext_concatGAP', 'save_results_path': 'results/mured/myconvnext_2layer_concatGAP.csv', 'dataset': 'mured', 'transformer_layer': 2},\n",
    "    {'model': 'myconvnext_concatGAP', 'save_results_path': 'results/mured/myconvnext_3layer_concatGAP.csv', 'dataset': 'mured', 'transformer_layer': 3},\n",
    "    {'model': 'vit', 'save_results_path': 'results/mured/vit-l_warmup.csv', 'dataset': 'mured'},\n",
    "    {'model': 'efficientnet', 'save_results_path': 'results/mured/efficientnet-v2.csv', 'dataset': 'mured'},\n",
    "    {'model': 'maxvit', 'save_results_path': 'results/mured/maxvit-b.csv', 'dataset': 'mured'},\n",
    "    {'model': 'coatnet', 'save_results_path': 'results/mured/coatnet.csv', 'dataset': 'mured'},\n",
    "    {'model': 'q2l', 'save_results_path': 'results/mured/q2l_swinL.csv', 'dataset': 'mured'},\n",
    "    {'model': 'mcar', 'save_results_path': 'results/mured/mcar_resnet101.csv', 'dataset': 'mured'},\n",
    "    {'model': 'ctran', 'save_results_path': 'results/mured/ctran_resnet.csv', 'dataset': 'mured', 'ctran_model': True},\n",
    "    {'model': 'add_gcn', 'save_results_path': 'results/mured/add_gcn.csv', 'dataset': 'mured'},\n",
    "    # {'model': 'model3', 'lr': 0.0005, 'dataset': 'mured', 'loss': 'asymmetric', 'ctran_model': True},\n",
    "    # Add more parameter sets as needed\n",
    "]\n",
    "\n",
    "# Run models with different parameter sets\n",
    "for params in parameter_sets:\n",
    "    args = Args(**params)\n",
    "    run_model(args)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "parameter_sets = [\n",
    "    {'model': 'q2l', 'save_results_path': 'results/mured/q2l_CvT.csv', 'dataset': 'mured', 'batch_size': 8},\n",
    "    {'model': 'myconvnext_concatGAP', 'save_results_path': 'results/mured/myconvnext_1layer_concatGAP_myproposed_kmean2_10.csv', 'dataset': 'mured', 'transformer_layer': 1, 'data_aug': 'myproposed_kmean2_10'},\n",
    "    {'model': 'myconvnext_concatGAP', 'save_results_path': 'results/mured/myconvnext_2layer_concatGAP_myproposed_kmean2_20.csv', 'dataset': 'mured', 'transformer_layer': 2, 'data_aug': 'myproposed_kmean2_20'},\n",
    "    {'model': 'myconvnext_concatGAP', 'save_results_path': 'results/mured/myconvnext_3layer_concatGAP_myproposed_kmean2_30.csv', 'dataset': 'mured', 'transformer_layer': 3, 'data_aug': 'myproposed_kmean2_30'},\n",
    "    {'model': 'myconvnext_concatGAP', 'save_results_path': 'results/mured/myconvnext_3layer_concatGAP_myproposed_kmean2_40.csv', 'dataset': 'mured', 'transformer_layer': 3, 'data_aug': 'myproposed_kmean2_40'},\n",
    "    {'model': 'myconvnext_concatGAP', 'save_results_path': 'results/mured/myconvnext_3layer_concatGAP_myproposed_kmean2_50.csv', 'dataset': 'mured', 'transformer_layer': 3, 'data_aug': 'myproposed_kmean2_50'},\n",
    "    # Add more parameter sets as needed\n",
    "]\n",
    "\n",
    "# Run models with different parameter sets\n",
    "for params in parameter_sets:\n",
    "    args = Args(**params)\n",
    "    run_model(args)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "parameter_sets = [\n",
    "    {'model': 'myconvnext_concatGAP', 'save_results_path': 'results/mured/myconvnext_1layer_concatGAP_myproposed_kmean2_10_focal_loss.csv', 'dataset': 'mured', 'transformer_layer': 1, 'data_aug': 'myproposed_kmean2_10', 'loss': 'focal_loss'},\n",
    "    {'model': 'myconvnext_concatGAP', 'save_results_path': 'results/mured/myconvnext_2layer_concatGAP_myproposed_kmean2_20_asymmetric_loss.csv', 'dataset': 'mured', 'transformer_layer': 2, 'data_aug': 'myproposed_kmean2_20', 'loss': 'asymmetric_loss'},\n",
    "    {'model': 'myconvnext_concatGAP', 'save_results_path': 'results/mured/myconvnext_3layer_concatGAP_myproposed_kmean2_30_poly_ce.csv', 'dataset': 'mured', 'transformer_layer': 3, 'data_aug': 'myproposed_kmean2_30', 'loss': 'poly_ce'},\n",
    "    {'model': 'myconvnext_concatGAP', 'save_results_path': 'results/mured/myconvnext_3layer_concatGAP_myproposed_kmean2_50_poly_focal.csv', 'dataset': 'mured', 'transformer_layer': 3, 'data_aug': 'myproposed_kmean2_50', 'loss': 'poly_focal'},\n",
    "    # Add more parameter sets as needed\n",
    "]\n",
    "\n",
    "# Run models with different parameter sets\n",
    "for params in parameter_sets:\n",
    "    args = Args(**params)\n",
    "    run_model(args)\n",
    "    print()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multilabel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
