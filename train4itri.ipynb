{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LambdaLR, StepLR\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, f1_score, average_precision_score, precision_score, recall_score\n",
    "from sklearn.model_selection import KFold\n",
    "import copy\n",
    "from tqdm import tqdm \n",
    "\n",
    "# Custom imports\n",
    "from utils import *\n",
    "from dataloaders.multilabel_dataset import MultilabelDataset\n",
    "from loss_functions.focal import FocalLoss\n",
    "from loss_functions.asymmetric import AsymmetricLossOptimized\n",
    "from models.resnet import ResNet50, ResNet152\n",
    "from models.densenet import DenseNet169, DenseNet161, DenseNet121\n",
    "from models.mobilenet import MobileNetV2\n",
    "from models.efficientnet import EfficientNetB3, EfficientNetB5, EfficientNetB7, EfficientNet_v2\n",
    "from models.inception import InceptionV3\n",
    "from models.vit import ViTForMultiLabelClassification, ViT\n",
    "from models.c_tran.ctran import CTranModel\n",
    "from models.utils import custom_replace\n",
    "from models.swin_transformer import SwinTransformer\n",
    "from models.convnext import ConvNeXt\n",
    "from models.mydensenet import myDenseNet1, myDenseNet2, myDenseNet3, myDenseNet4\n",
    "from models.myconvnext import ConvNeXtTransformer, ConvNeXtTransformer_concatGAP\n",
    "from models.maxvit import MaxViT\n",
    "# from models.mvit import MViT_v2\n",
    "from models.coatnet import CoAtNet\n",
    "from models.add_gcn import ADD_GCN\n",
    "from models.query2label.query2label import build_q2l\n",
    "from models.ml_decoder import create_model\n",
    "from models.tresnet import create_tresnet_model\n",
    "\n",
    "# GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "prefetch_factor = 64\n",
    "num_workers = 28\n",
    "# selected_data  = 'augmented' # 'original' or 'augmented' to evaluate the model on the original or augmented dataset\n",
    "# auc_fig_path = 'results/auc/densenet161.png'\n",
    "# results_path = 'results/densenet161_90.csv'\n",
    "# ctran_model = False # True for CTran, False for CNN\n",
    "loss_labels = 'all' # 'all' or 'unk'for all labels or only unknown labels loss respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transforms\n",
    "## Transformations adapted for the dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((384, 384)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(180),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    # transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset2train(dataset_name, data_aug=None):\n",
    "    if data_aug:\n",
    "        # print(f\"[Data Augmentation: {data_aug}]\")\n",
    "        if dataset_name == 'rfmid':\n",
    "            # RFMiD dataset\n",
    "            num_classes = 29\n",
    "            normal_class_index = 0\n",
    "            training_labels_path = f\"data/fundus/RFMiD/Training_Set/{data_aug}_new_RFMiD_Training_Labels.csv\"\n",
    "            evaluation_labels_path = 'data/fundus/RFMiD/Evaluation_Set/new_RFMiD_Validation_Labels.csv'\n",
    "            training_images_dir = 'data/fundus/RFMiD/Training_Set/Training'\n",
    "            evaluation_images_dir = 'data/fundus/RFMiD/Evaluation_Set/Validation'\n",
    "            da_training_images_dir = f\"data/fundus/RFMiD/Training_Set/{data_aug}\"\n",
    "        elif dataset_name == 'mured':\n",
    "            # MuReD dataset\n",
    "            num_classes = 20\n",
    "            normal_class_index = 1\n",
    "            training_labels_path = f\"data/fundus/MuReD/{data_aug}_train_data.csv\"\n",
    "            evaluation_labels_path = 'data/fundus/MuReD/test_data.csv'\n",
    "            training_images_dir = 'data/fundus/MuReD/images/images'\n",
    "            evaluation_images_dir = 'data/fundus/MuReD/images/images'\n",
    "            da_training_images_dir = f\"data/fundus/MuReD/images/{data_aug}\"\n",
    "    else:\n",
    "        # print(\"[Original Data]\")\n",
    "        if dataset_name == 'rfmid':\n",
    "            # RFMiD dataset\n",
    "            num_classes = 29\n",
    "            normal_class_index = 0\n",
    "            training_labels_path = 'data/fundus/RFMiD/Training_Set/new_RFMiD_Training_Labels.csv'\n",
    "            evaluation_labels_path = 'data/fundus/RFMiD/Evaluation_Set/new_RFMiD_Validation_Labels.csv'\n",
    "            training_images_dir = 'data/fundus/RFMiD/Training_Set/Training'\n",
    "            evaluation_images_dir = 'data/fundus/RFMiD/Evaluation_Set/Validation'\n",
    "            da_training_images_dir = 'data/fundus/RFMiD/Training_Set/Training'\n",
    "        elif dataset_name == 'mured':\n",
    "            # MuReD dataset\n",
    "            num_classes = 20\n",
    "            normal_class_index = 1\n",
    "            training_labels_path = 'data/fundus/MuReD/train_data.csv'\n",
    "            evaluation_labels_path = 'data/fundus/MuReD/test_data.csv'\n",
    "            training_images_dir = 'data/fundus/MuReD/images/images'\n",
    "            evaluation_images_dir = 'data/fundus/MuReD/images/images'\n",
    "            da_training_images_dir = 'data/fundus/MuReD/images/images' # 'data/fundus/MuReD/images/xxxx' or None\n",
    "        \n",
    "    return num_classes, training_labels_path, evaluation_labels_path, training_images_dir, evaluation_images_dir, da_training_images_dir, normal_class_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "def get_dataset(num_classes, batch_size, training_labels_path, training_images_dir, da_training_images_dir, evaluation_labels_path, evaluation_images_dir):\n",
    "    # train dataset\n",
    "    train_dataset = MultilabelDataset(ann_dir=training_labels_path,\n",
    "                                root_dir=training_images_dir,\n",
    "                                num_labels=num_classes,\n",
    "                                transform=transform, known_labels=1, testing=False, da_root_dir=da_training_images_dir)\n",
    "\n",
    "    # val dataset\n",
    "    test_dataset = MultilabelDataset(ann_dir=evaluation_labels_path,\n",
    "                                root_dir=evaluation_images_dir,\n",
    "                                num_labels=num_classes,\n",
    "                                transform=transform, known_labels=0, testing=True)\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, prefetch_factor=prefetch_factor, num_workers=num_workers)\n",
    "    return train_dataset, test_dataset, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "def get_model(model_name, transformer_layer, num_classes):\n",
    "    if model_name == 'resnet':\n",
    "        model = ResNet152(num_classes).to(device)\n",
    "    elif model_name == 'densenet':\n",
    "        model = DenseNet121(num_classes).to(device)\n",
    "        # model = DenseNet161(num_classes).to(device)\n",
    "    elif model_name == 'mobilenet':\n",
    "        model = MobileNetV2(num_classes).to(device)\n",
    "    elif model_name == 'efficientnet':\n",
    "        model = EfficientNet_v2(num_classes).to(device)\n",
    "    elif model_name == 'inception':\n",
    "        model = InceptionV3(num_classes).to(device)\n",
    "    elif model_name == 'vit':\n",
    "        model = ViT(num_labels=num_classes).to(device)\n",
    "    elif model_name == 'ctran':\n",
    "        model = CTranModel(num_labels=num_classes,use_lmt=True,pos_emb=False,layers=3,heads=4,dropout=0.1).to(device)\n",
    "    elif model_name == 'swin':\n",
    "        model = SwinTransformer(num_classes=num_classes).to(device)\n",
    "    elif model_name == 'convnext':\n",
    "        model = ConvNeXt(num_classes=num_classes).to(device)\n",
    "    elif model_name == 'mydensenet4':\n",
    "        model = myDenseNet4(num_classes).to(device)\n",
    "    elif model_name == 'myconvnext':\n",
    "        model = ConvNeXtTransformer(num_classes, num_transformer_layers=transformer_layer).to(device)\n",
    "    elif model_name == 'myconvnext_concatGAP':\n",
    "        model = ConvNeXtTransformer_concatGAP(num_classes, num_transformer_layers=transformer_layer).to(device)\n",
    "    elif model_name == 'maxvit':\n",
    "        model = MaxViT(num_classes=num_classes).to(device)\n",
    "    elif model_name == 'mvit':\n",
    "        pass\n",
    "        # model = MViT_v2(num_classes=num_classes).to(device)\n",
    "    elif model_name == 'coatnet':\n",
    "        model = CoAtNet(num_classes=num_classes).to(device)\n",
    "    elif model_name == 'add_gcn':\n",
    "        model = ADD_GCN(num_classes=num_classes).to(device)\n",
    "    elif model_name == 'q2l':\n",
    "        model = build_q2l(num_class=num_classes).to(device)\n",
    "    elif model_name == 'ml_decoder':\n",
    "        model = create_model(num_classes=num_classes).to(device)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainset to train and validation (0.8, 0.2)   \n",
    "def train(model, train_dataset, learning_rate, batch_size, ctran_model=False, evaluation=False, weight_decay=False, warmup=False, loss='bce'):\n",
    "    num_epochs = 35\n",
    "    if weight_decay:\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "        # optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "    else:\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "    # Loss function\n",
    "    if loss == 'focal_loss':\n",
    "        print(\"[Focal Loss]\")\n",
    "        criterion = FocalLoss()\n",
    "    elif loss == 'asymmetric_loss':\n",
    "        print(\"[Asymmetric Loss]\")\n",
    "        criterion = AsymmetricLossOptimized()\n",
    "    else:\n",
    "        print(\"[BCE Loss]\")\n",
    "        criterion = nn.BCEWithLogitsLoss(reduction='sum')\n",
    "    \n",
    "    if warmup:\n",
    "        num_epochs += 5\n",
    "        warmup_scheduler = LambdaLR(optimizer, lr_lambda=linear_warmup)\n",
    "        \n",
    "    step_scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    # scheduler = StepLR(optimizer, step_size=10, gamma=0.1) \n",
    "        \n",
    "    if evaluation:\n",
    "        # torch.manual_seed(13)\n",
    "        total_size = len(train_dataset)\n",
    "        val_size = int(total_size * 0.2)\n",
    "        train_size = total_size - val_size\n",
    "        train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "        \n",
    "        # train_label_counts = count_labels(train_dataset, num_classes)\n",
    "        # val_label_counts = count_labels(val_dataset, num_classes)\n",
    "        # sorted_train_label_counts = dict(sorted(train_label_counts.items()))\n",
    "        # sorted_val_label_counts = dict(sorted(val_label_counts.items()))\n",
    "        # print(\"Train Label Counts:     \", sorted_train_label_counts)\n",
    "        # print(\"Validation Label Counts:\", sorted_val_label_counts)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, prefetch_factor=prefetch_factor, num_workers=num_workers)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, prefetch_factor=prefetch_factor, num_workers=num_workers)\n",
    "    else:\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, prefetch_factor=prefetch_factor, num_workers=num_workers)\n",
    "\n",
    "    best_train_loss = float('inf')\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    for epoch in tqdm(range(num_epochs), desc='Epoch'):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            if ctran_model:\n",
    "                labels = batch['labels'].float()\n",
    "                images = batch['image'].float()\n",
    "                mask = batch['mask'].float()\n",
    "                unk_mask = custom_replace(mask,1,0,0)\n",
    "                mask_in = mask.clone()\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs,_,_ = model(images.to(device),mask_in.to(device))\n",
    "                \n",
    "                loss =  F.binary_cross_entropy_with_logits(outputs.view(labels.size(0),-1),labels.cuda(),reduction='none')\n",
    "                if loss_labels == 'unk': \n",
    "                    # only use unknown labels for loss\n",
    "                    loss_out = (unk_mask.cuda()*loss).sum()\n",
    "                else: \n",
    "                    # use all labels for loss\n",
    "                    loss_out = loss.sum()\n",
    "                    \n",
    "            else:\n",
    "                inputs, labels = batch['image'].to(device), batch['labels'].to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                # print(outputs.shape, labels.shape)\n",
    "                # loss_out = F.binary_cross_entropy_with_logits(outputs, labels, reduction='none').sum() # sigmoid + BCELoss\n",
    "                loss_out = criterion(outputs, labels)\n",
    "            \n",
    "            train_loss += loss_out.item()\n",
    "            loss_out.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        # scheduler.step()\n",
    "        if epoch < 5:\n",
    "            if warmup:\n",
    "                # print(warmup_scheduler.get_last_lr())\n",
    "                warmup_scheduler.step()\n",
    "            else:\n",
    "                step_scheduler.step()\n",
    "                # print(step_scheduler.get_last_lr())\n",
    "        else:\n",
    "            step_scheduler.step()\n",
    "            # print(step_scheduler.get_last_lr())\n",
    "\n",
    "        if not evaluation:\n",
    "            current_train_loss = train_loss / len(train_loader)\n",
    "            if current_train_loss < best_train_loss:\n",
    "                best_train_loss = current_train_loss\n",
    "                best_model_state = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss/len(train_loader):.6f}')\n",
    "            continue\n",
    "    \n",
    "        # Evaluate the model on the validation set\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        # correct_predictions = 0\n",
    "        # total_jaccard_index = 0.0\n",
    "        # total_samples = 0\n",
    "        auc_scores = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            all_preds = []\n",
    "            all_labels = []\n",
    "            all_preds_4 = []\n",
    "            all_labels_4 = []\n",
    "            all_preds_5 = []\n",
    "            all_labels_5 = []\n",
    "            for batch in val_loader:\n",
    "                if ctran_model:\n",
    "                    labels = batch['labels'].float()\n",
    "                    images = batch['image'].float()\n",
    "                    mask = batch['mask'].float()\n",
    "                    mask_in = mask.clone()\n",
    "                    unk_mask = custom_replace(mask,1,0,0)\n",
    "                    \n",
    "                    outputs,int_pred,attns = model(images.to(device),mask_in.to(device))\n",
    "                    \n",
    "                    loss = F.binary_cross_entropy_with_logits(outputs.view(labels.size(0),-1),labels.cuda(), reduction='none')\n",
    "                    loss_out = (unk_mask.cuda()*loss).sum()\n",
    "                else:\n",
    "                    inputs, labels = batch['image'].to(device), batch['labels'].to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    # loss_out = F.binary_cross_entropy_with_logits(outputs, labels, reduction='none').sum()\n",
    "                    loss_out = criterion(outputs, labels)\n",
    "                    \n",
    "                val_loss += loss_out.item()\n",
    "\n",
    "                # Calculate accuracy\n",
    "                ## method 1. Strictly Accuracy\n",
    "                # predicted_labels = (outputs > 0.5).float()\n",
    "                # correct_predictions += (predicted_labels == labels).all(dim=1).sum().item()\n",
    "                # total_samples += labels.size(0)\n",
    "                \n",
    "                ## method 2. Jaccard Accuracy\n",
    "                # predicted = (outputs > 0.5).bool()\n",
    "                # labels_bool = labels.bool()\n",
    "                # intersection = (predicted & labels_bool).float().sum(dim=1)\n",
    "                # union = (predicted | labels_bool).float().sum(dim=1)\n",
    "                # jaccard_index_per_example = intersection / union\n",
    "                # jaccard_index_per_example[union == 0] = 1.0\n",
    "                # total_jaccard_index += jaccard_index_per_example.sum().item()\n",
    "                # total_samples += labels.size(0)\n",
    "                \n",
    "                ## method 3. AUC\n",
    "                outputs_np = F.sigmoid(outputs).cpu().numpy()\n",
    "                # outputs_np = outputs.cpu().numpy()\n",
    "                labels_np = labels.cpu().numpy()\n",
    "                all_preds.extend(outputs_np)\n",
    "                all_labels.extend(labels_np)\n",
    "                \n",
    "                ## method 4. mAP\n",
    "                all_preds_4.append(F.sigmoid(outputs).cpu())\n",
    "                # all_preds_4.append(outputs.cpu())\n",
    "                all_labels_4.append(labels.cpu())\n",
    "                \n",
    "                ## method 5. F1 Score\n",
    "                predicted = F.sigmoid(outputs).cpu() > 0.5\n",
    "                # predicted = outputs.cpu() > 0.5\n",
    "                all_preds_5.append(predicted.numpy())\n",
    "                all_labels_5.append(labels.cpu().numpy())\n",
    "\n",
    "        current_val_loss = val_loss / len(val_loader)\n",
    "        if current_val_loss < best_val_loss:\n",
    "            best_val_loss = current_val_loss\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        # if rfmid_ori:\n",
    "        #     print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss/len(train_loader):.6f}, Validation Loss: {val_loss/len(val_loader):.6f}')\n",
    "        #     continue\n",
    "        \n",
    "        ## method 1.\n",
    "        # accuracy = correct_predictions / total_samples\n",
    "        ## method 2.\n",
    "        # accuracy = total_jaccard_index / total_samples\n",
    "        ## method 3.\n",
    "        for i in range(labels_np.shape[1]):\n",
    "                label_specific_auc = roc_auc_score([label[i] for label in all_labels], [pred[i] for pred in all_preds])\n",
    "                auc_scores.append(label_specific_auc)\n",
    "        average_auc = sum(auc_scores) / len(auc_scores)\n",
    "        ## method 4. mAP\n",
    "        all_preds_4 = torch.cat(all_preds_4).numpy()\n",
    "        all_labels_4 = torch.cat(all_labels_4).numpy()\n",
    "        mAP = 0\n",
    "        for i in range(all_labels_4.shape[1]):\n",
    "            AP = average_precision_score(all_labels_4[:, i], all_preds_4[:, i])\n",
    "            mAP += AP\n",
    "\n",
    "        mAP /= all_labels_4.shape[1]\n",
    "        ## method 5. F1 Score\n",
    "        all_preds_5 = np.vstack(all_preds_5)\n",
    "        all_labels_5 = np.vstack(all_labels_5)\n",
    "        f1_macro = f1_score(all_labels_5, all_preds_5, average='macro')\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss/len(train_loader):.6f}, Validation Loss: {val_loss/len(val_loader):.6f}, F1_macro: {f1_macro:.3f}, mAP: {mAP:.3f}, Average AUC: {average_auc:.3f}')\n",
    "    return best_model_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "def evaluate(model, best_model_state, test_loader, results_path, evaluation_labels_path, dataset_name, normal_index=1, ctran_model=False, best_model=False):\n",
    "    if best_model:\n",
    "        print(\"------ Best model evaluation -----\")\n",
    "        model.load_state_dict(best_model_state)\n",
    "        \n",
    "    model.eval()\n",
    "    # correct_predictions = 0\n",
    "    # total_jaccard_index = 0.0\n",
    "    # total_samples = 0\n",
    "    auc_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        all_preds_4 = []\n",
    "        all_labels_4 = []\n",
    "        all_preds_5 = []\n",
    "        all_labels_5 = []\n",
    "        \n",
    "        for batch in test_loader:\n",
    "            if ctran_model:\n",
    "                labels = batch['labels'].float()\n",
    "                images = batch['image'].float()\n",
    "                mask = batch['mask'].float()\n",
    "                mask_in = mask.clone()\n",
    "                unk_mask = custom_replace(mask,1,0,0)\n",
    "                \n",
    "                outputs,int_pred,attns = model(images.to(device),mask_in.to(device))\n",
    "            else:\n",
    "                inputs, labels = batch['image'].to(device), batch['labels'].to(device)\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "            # Calculate accuracy\n",
    "            ## method 1. Strictly Accuracy\n",
    "            # predicted_labels = (outputs > 0.5).float()\n",
    "            # correct_predictions += (predicted_labels == labels).all(dim=1).sum().item()\n",
    "            # total_samples += labels.size(0)\n",
    "            \n",
    "            ## method 2. Jaccard Accuracy\n",
    "            # predicted = (outputs > 0.5).bool()\n",
    "            # labels_bool = labels.bool()\n",
    "            # intersection = (predicted & labels_bool).float().sum(dim=1)\n",
    "            # union = (predicted | labels_bool).float().sum(dim=1)\n",
    "            # jaccard_index_per_example = intersection / union\n",
    "            # jaccard_index_per_example[union == 0] = 1.0\n",
    "            # total_jaccard_index += jaccard_index_per_example.sum().item()\n",
    "            # total_samples += labels.size(0)\n",
    "            \n",
    "            ## method 3. AUC\n",
    "            outputs_np = F.sigmoid(outputs).cpu().numpy()\n",
    "            # outputs_np = outputs.cpu().numpy()\n",
    "            labels_np = labels.cpu().numpy()\n",
    "            all_preds.extend(outputs_np)\n",
    "            all_labels.extend(labels_np)\n",
    "            \n",
    "            ## method 4. mAP\n",
    "            all_preds_4.append(F.sigmoid(outputs).cpu())\n",
    "            # all_preds_4.append(outputs.cpu())\n",
    "            all_labels_4.append(labels.cpu())\n",
    "            \n",
    "            ## method 5. F1 Score\n",
    "            predicted = F.sigmoid(outputs).cpu() > 0.5\n",
    "            # predicted = outputs.cpu() > 0.5\n",
    "            all_preds_5.append(predicted.numpy())\n",
    "            all_labels_5.append(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "    ## method 1.\n",
    "    # accuracy = correct_predictions / total_samples\n",
    "    ## method 2.\n",
    "    # accuracy = total_jaccard_index / total_samples\n",
    "    ## method 3.\n",
    "    # print(len(all_preds), all_preds[0].shape, labels_np.shape)\n",
    "    for i in range(labels_np.shape[1]):\n",
    "        # print(len(all_labels))\n",
    "        # print([label[i] for label in all_labels], [pred[i] for pred in all_preds])\n",
    "        label_specific_auc = roc_auc_score([label[i] for label in all_labels], [pred[i] for pred in all_preds])\n",
    "        auc_scores.append(label_specific_auc)\n",
    "        \n",
    "        # Precision and Recall\n",
    "        label_specific_precision = precision_score([label[i] for label in all_labels], [pred[i] > 0.5 for pred in all_preds], zero_division=0)\n",
    "        label_specific_recall = recall_score([label[i] for label in all_labels], [pred[i] > 0.5 for pred in all_preds], zero_division=0)\n",
    "        precision_scores.append(label_specific_precision)\n",
    "        recall_scores.append(label_specific_recall)\n",
    "        \n",
    "    average_auc = sum(auc_scores) / len(auc_scores)\n",
    "    average_precision = sum(precision_scores) / len(precision_scores)\n",
    "    average_recall = sum(recall_scores) / len(recall_scores)\n",
    "    ## method 4. mAP\n",
    "    all_preds_4 = torch.cat(all_preds_4).numpy()\n",
    "    all_labels_4 = torch.cat(all_labels_4).numpy()\n",
    "    mAP = 0\n",
    "    mAP_per_label = []\n",
    "    for i in range(all_labels_4.shape[1]):\n",
    "        AP = average_precision_score(all_labels_4[:, i], all_preds_4[:, i])\n",
    "        mAP_per_label.append(AP)\n",
    "        mAP += AP\n",
    "\n",
    "    mAP /= all_labels_4.shape[1]\n",
    "    ## method 5. F1 Score\n",
    "    all_preds_5 = np.vstack(all_preds_5)\n",
    "    all_labels_5 = np.vstack(all_labels_5)\n",
    "    f1_macro = f1_score(all_labels_5, all_preds_5, average='macro')\n",
    "    f1_list = list(f1_score(all_labels_5, all_preds_5, average=None))\n",
    "    \n",
    "    if dataset_name == 'rfmid':\n",
    "        os.makedirs('results/rfmid', exist_ok=True)\n",
    "    elif dataset_name == 'mured':\n",
    "        os.makedirs('results/mured', exist_ok=True)\n",
    "    avg_results = result2csv(results_path, evaluation_labels_path, precision_scores, recall_scores, f1_list, mAP_per_label, auc_scores)\n",
    "    # print(f'Evaluation - Average Precision: {average_precision:.3f}, Average Recall: {average_recall:.3f}, F1_macro: {f1_macro:.3f}, mAP: {mAP:.3f}, Average AUC: {average_auc:.3f}, ML Scores: {(mAP + average_auc) / 2:.3f}')\n",
    "    \n",
    "    normal_auc = auc_scores.pop(normal_index)\n",
    "    average_auc = sum(auc_scores) / len(auc_scores)\n",
    "    normal_f1 = f1_list.pop(normal_index)\n",
    "    f1_macro = sum(f1_list) / len(f1_list)\n",
    "    mAP_per_label.pop(normal_index)\n",
    "    mAP = sum(mAP_per_label) / len(mAP_per_label)\n",
    "    ML_score = (mAP + average_auc) / 2\n",
    "    eval_results = [f1_macro, mAP, average_auc, ML_score, normal_f1, normal_auc, (ML_score + normal_auc) / 2]\n",
    "    eval_results = [str(round(result, 3)) for result in eval_results]\n",
    "    results2allcsv(results_path, eval_results, avg_results, dataset_name)\n",
    "    print(f'===== Evaluation results =====')\n",
    "    print(f'Average Precision: {avg_results[0]}, Average Recall: {avg_results[1]}, F1_macro: {avg_results[2]}, mAP: {avg_results[3]}, Average AUC: {avg_results[4]}')\n",
    "    print(f'ML_F1: {f1_macro:.3f}, ML_mAP: {mAP:.3f}, ML_AUC: {average_auc:.3f}, ML_Score: {ML_score:.3f}, Bin_F1: {normal_f1:.3f}, Bin_AUC: {normal_auc:.3f}, Model_Score: {(ML_score + normal_auc) / 2:.3f}')\n",
    "    # plot_auc_curve(all_preds, all_labels, evaluation_labels_path, auc_fig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(args):\n",
    "    num_classes, training_labels_path, evaluation_labels_path, training_images_dir, evaluation_images_dir, da_training_images_dir, normal_class_index = dataset2train(args.dataset, args.data_aug)\n",
    "    train_dataset, test_dataset, test_loader = get_dataset(num_classes=num_classes, batch_size=args.batch_size, training_labels_path=training_labels_path, training_images_dir=training_images_dir, da_training_images_dir=da_training_images_dir, evaluation_labels_path=evaluation_labels_path, evaluation_images_dir=evaluation_images_dir)\n",
    "    model = get_model(args.model, args.transformer_layer, num_classes)\n",
    "    print(f\"===== Model: {model.__class__.__name__} =====\")\n",
    "    print(f\"<training_labels_path: {training_labels_path}>\")\n",
    "    print(\"******************** Training   ********************\")\n",
    "    if args.plm:\n",
    "        best_model_state = train_plm(model, train_dataset, args.lr, ctran_model=args.ctran_model, warmup=args.warmup, evaluation=args.val, num_classes=num_classes, batch_size=args.batch_size, prefetch_factor=prefetch_factor, num_workers=num_workers, device=device, loss=args.loss)\n",
    "    else:\n",
    "        best_model_state = train(model, train_dataset, args.lr, batch_size=args.batch_size, ctran_model=args.ctran_model, evaluation=args.val, weight_decay=args.weight_decay, warmup=args.warmup, loss=args.loss)\n",
    "    # best_model_state = train_kfold(model, train_dataset, args.lr, ctran_model=args.ctran_model)\n",
    "    print(\"******************** Testing ********************\")\n",
    "    evaluate(model, best_model_state, test_loader, args.save_results_path, evaluation_labels_path, args.dataset, normal_index=normal_class_index, ctran_model=args.ctran_model)\n",
    "    # evaluate(model, best_model_state, test_loader, args.save_results_path, ctran_model=args.ctran_model, best_model =True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Model: DenseNet121 =====\n",
      "<training_labels_path: data/fundus/MuReD/train_data.csv>\n",
      "******************** Training   ********************\n",
      "--BCE Loss--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   3%|▎         | 1/35 [00:17<10:06, 17.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35, Training Loss: 95.998035, Validation Loss: 60.944141, F1_macro: 0.055, mAP: 0.260, Average AUC: 0.791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   6%|▌         | 2/35 [00:33<09:10, 16.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/35, Training Loss: 54.457677, Validation Loss: 52.148422, F1_macro: 0.138, mAP: 0.377, Average AUC: 0.859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   9%|▊         | 3/35 [00:49<08:46, 16.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/35, Training Loss: 48.854779, Validation Loss: 47.474943, F1_macro: 0.183, mAP: 0.462, Average AUC: 0.890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  11%|█▏        | 4/35 [01:06<08:26, 16.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/35, Training Loss: 45.689868, Validation Loss: 46.395409, F1_macro: 0.184, mAP: 0.462, Average AUC: 0.893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  14%|█▍        | 5/35 [01:22<08:09, 16.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/35, Training Loss: 43.694674, Validation Loss: 44.162323, F1_macro: 0.210, mAP: 0.482, Average AUC: 0.908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  17%|█▋        | 6/35 [01:38<07:53, 16.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/35, Training Loss: 41.283934, Validation Loss: 42.057004, F1_macro: 0.292, mAP: 0.520, Average AUC: 0.916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  17%|█▋        | 6/35 [01:51<08:59, 18.61s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m params \u001b[38;5;129;01min\u001b[39;00m parameter_sets:\n\u001b[1;32m     28\u001b[0m     args \u001b[38;5;241m=\u001b[39m Args(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m---> 29\u001b[0m     \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m, in \u001b[0;36mrun_model\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m      9\u001b[0m     best_model_state \u001b[38;5;241m=\u001b[39m train_plm(model, train_dataset, args\u001b[38;5;241m.\u001b[39mlr, ctran_model\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mctran_model, warmup\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mwarmup, evaluation\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mval, num_classes\u001b[38;5;241m=\u001b[39mnum_classes, batch_size\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch_size, prefetch_factor\u001b[38;5;241m=\u001b[39mprefetch_factor, num_workers\u001b[38;5;241m=\u001b[39mnum_workers, device\u001b[38;5;241m=\u001b[39mdevice, loss\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mloss)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 11\u001b[0m     best_model_state \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctran_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctran_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarmup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarmup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# best_model_state = train_kfold(model, train_dataset, args.lr, ctran_model=args.ctran_model)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m******************** Testing ********************\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 81\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dataset, learning_rate, batch_size, ctran_model, evaluation, weight_decay, warmup, loss)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;66;03m# print(outputs.shape, labels.shape)\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# loss_out = F.binary_cross_entropy_with_logits(outputs, labels, reduction='none').sum() # sigmoid + BCELoss\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     loss_out \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 81\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss_out\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m loss_out\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     83\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    def __init__(self, model='myconvnext_concatGAP', save_results_path='results/myconvnext_concatGAP.csv', ctran_model=False,\n",
    "                 lr=0.0001, batch_size=16, val=False, transformer_layer=2, dataset='mured', weight_decay=False, warmup=False,\n",
    "                 data_aug=None, plm=False, loss='bce'):\n",
    "        self.model = model\n",
    "        self.save_results_path = save_results_path\n",
    "        self.ctran_model = ctran_model\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.val = val\n",
    "        self.transformer_layer = transformer_layer\n",
    "        self.dataset = dataset\n",
    "        self.weight_decay = weight_decay\n",
    "        self.warmup = warmup\n",
    "        self.data_aug = data_aug\n",
    "        self.plm = plm\n",
    "        self.loss = loss\n",
    "\n",
    "parameter_sets = [\n",
    "    {'model': 'densenet', 'save_results_path': 'results/mured/densenet.csv', 'dataset': 'mured', 'val': True},\n",
    "    {'model': 'ctran', 'save_results_path': 'results/mured/ctran_resnet.csv', 'dataset': 'mured', 'ctran_model': True, 'val': True},\n",
    "    # {'model': 'model3', 'lr': 0.0005, 'dataset': 'mured', 'loss': 'asymmetric', 'ctran_model': True},\n",
    "    # Add more parameter sets as needed\n",
    "]\n",
    "\n",
    "# Run models with different parameter sets\n",
    "for params in parameter_sets:\n",
    "    args = Args(**params)\n",
    "    run_model(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multilabel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
