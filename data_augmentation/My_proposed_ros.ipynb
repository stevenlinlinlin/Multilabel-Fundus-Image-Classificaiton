{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import albumentations as A\n",
    "# import cv2\n",
    "# import os\n",
    "# from pathlib import Path\n",
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DR        396\n",
       "NORMAL    395\n",
       "MH        135\n",
       "ODC       211\n",
       "TSLN      125\n",
       "ARMD      126\n",
       "DN        130\n",
       "MYA        71\n",
       "BRVO       63\n",
       "ODP        50\n",
       "CRVO       44\n",
       "CNV        48\n",
       "RS         47\n",
       "ODE        46\n",
       "LS         37\n",
       "CSR        29\n",
       "HTR        28\n",
       "ASR        26\n",
       "CRS        24\n",
       "OTHER     209\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels_df = pd.read_csv('../data/fundus/MuReD/train_data.csv')\n",
    "# labels_df['ID'] = labels_df['ID'].astype(str)\n",
    "# class_counts = labels_df.iloc[:, 1:].sum(axis=0)\n",
    "# class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = A.Compose([\n",
    "#     A.Rotate(limit=45, p=0.5),  # 旋轉，概率為0.5\n",
    "#     A.HorizontalFlip(p=0.5),    # 水平翻轉，概率為0.5\n",
    "# ])\n",
    "\n",
    "# transform = A.Compose([\n",
    "#     A.OneOf([\n",
    "#         A.Rotate(limit=45, p=1.0),  # 旋转，当被选择时应用的概率为1.0\n",
    "#         A.HorizontalFlip(p=1.0),    # 水平翻转，当被选择时应用的概率为1.0\n",
    "#         A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=1.0),  # 随机亮度对比度调整\n",
    "#         A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=1.0)  # 色调饱和度调整\n",
    "#     ], p=1)\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRS\n",
      "ASR\n",
      "CSR\n",
      "LS\n",
      "HTR\n",
      "ODE\n",
      "RS\n",
      "CRVO\n",
      "ODP\n",
      "BRVO\n",
      "CNV\n",
      "MYA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DR        474\n",
       "NORMAL    395\n",
       "MH        147\n",
       "ODC       248\n",
       "TSLN      135\n",
       "ARMD      174\n",
       "DN        156\n",
       "MYA       100\n",
       "BRVO      100\n",
       "ODP       100\n",
       "CRVO      100\n",
       "CNV       100\n",
       "RS        100\n",
       "ODE       103\n",
       "LS        113\n",
       "CSR       103\n",
       "HTR       107\n",
       "ASR       156\n",
       "CRS       101\n",
       "OTHER     263\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # images_path = Path(\"../data/fundus/MuReD/images/images\") # training set images path\n",
    "# # da_images_path = Path(\"../data/fundus/MuReD/images/ros\") # augmented images path\n",
    "\n",
    "# class_add_count = 100\n",
    "# ID_name = 1\n",
    "# while True:\n",
    "#     class_counts = labels_df.iloc[:, 1:].sum(axis=0)\n",
    "#     sorted_class_counts = class_counts.sort_values()\n",
    "#     if all(sorted_class_counts >= class_add_count):\n",
    "#         break \n",
    "    \n",
    "#     for class_name, count in sorted_class_counts.items():\n",
    "#         # print(class_name)\n",
    "#         adds = 0\n",
    "#         images_to_augment = labels_df[labels_df[class_name] == 1]\n",
    "#         while count + adds < class_add_count:\n",
    "#             img_rows = images_to_augment.sample(n=min(class_add_count-count-adds, count))\n",
    "#             # print(img_rows)\n",
    "#             for index, img_row in img_rows.iterrows():\n",
    "#                 # img_name = img_row['ID']\n",
    "#                 # if img_name.startswith('DA'):\n",
    "#                 #     continue\n",
    "                \n",
    "#                 # image_path = images_path / f\"{img_name}.png\" if os.path.exists(images_path / f\"{img_name}.png\") else images_path / f\"{img_name}.tif\"\n",
    "#                 # image = cv2.imread(str(image_path))\n",
    "#                 # if image is not None:\n",
    "#                 #     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                    \n",
    "#                     # transformed = transform(image=image)\n",
    "#                     # transformed_image = transformed[\"image\"]\n",
    "\n",
    "#                     # new_img_name = f\"DA_{ID_name}.png\"\n",
    "#                     # ID_name += 1\n",
    "#                     # new_img_path = da_images_path / new_img_name\n",
    "#                     # cv2.imwrite(str(new_img_path), cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "                    \n",
    "#                 new_row = img_row.copy()\n",
    "#                 adds += 1\n",
    "#                 # new_row['ID'] = new_img_name.replace('.png', '')\n",
    "#                 labels_df = labels_df._append(new_row, ignore_index=True)\n",
    "\n",
    "#         break\n",
    "#     # print(class_counts)\n",
    "#     # print(\"xxxxxxxxxxxxxxxxxxxxxxxx\")\n",
    "            \n",
    "# class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels_df.to_csv('../data/fundus/MuReD/ros100_train_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------threshold : 8041.0-----------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MHL        9199\n",
       "ERM        8041\n",
       "VH         9737\n",
       "AH         8509\n",
       "RAO       10364\n",
       "RVO        8148\n",
       "ODC       15144\n",
       "ON         8116\n",
       "AMD       13470\n",
       "RT         8149\n",
       "MYA       27661\n",
       "CSR        8336\n",
       "TV        11081\n",
       "RP        11131\n",
       "normal     8041\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# df = pd.read_csv('../data/fundus/ITRI/train_itri.csv')\n",
    "df = pd.read_csv('../data/fundus/MuReD/train_data.csv')\n",
    "label_counts = df.iloc[:, 1:].sum(axis=0)\n",
    "\n",
    "# threshold = label_counts.max() * 0.2\n",
    "# print(f\"---------threshold : {threshold}-----------\")\n",
    "\n",
    "# minority_labels = label_counts[label_counts < threshold].index.tolist()\n",
    "\n",
    "def augment_data(df, label_counts):\n",
    "    threshold = label_counts.max() * 0.2\n",
    "    print(f\"---------threshold : {threshold}-----------\")\n",
    "    minority_labels = label_counts[label_counts < threshold].index.tolist()\n",
    "    needs_augmentation = {label: int(threshold - count) for label, count in label_counts.items() if label in minority_labels and count < threshold}\n",
    "        \n",
    "    while any(needs > 0 for needs in needs_augmentation.values()):\n",
    "        label, needs = max(needs_augmentation.items(), key=lambda item: item[1])\n",
    "        if needs > 0:\n",
    "            minority_samples = df[df[label] == 1].copy()\n",
    "            samples_to_add = resample(minority_samples, n_samples=needs, replace=True)\n",
    "\n",
    "            df = pd.concat([df, samples_to_add], ignore_index=True)\n",
    "            label_counts = df.iloc[:, 1:].sum(axis=0)\n",
    "            needs_augmentation = {label: int(threshold - count) for label, count in label_counts.items() if label in minority_labels and count < threshold}\n",
    "    return df\n",
    "\n",
    "df_augmented = augment_data(df, label_counts)\n",
    "\n",
    "df_augmented.iloc[:, 1:].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_augmented.to_csv('../data/fundus/MuReD/ros02_train_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multilabel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
