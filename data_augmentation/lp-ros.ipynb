{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1764"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = pd.read_csv('../data/fundus/MuReD/train_data.csv')\n",
    "images_path = Path('../data/fundus/MuReD/images/images')\n",
    "da_images_path = Path('../data/fundus/MuReD/images/lpros030')\n",
    "len(labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    A.OneOf([\n",
    "        A.Rotate(limit=45, p=1.0),  # 旋转，当被选择时应用的概率为1.0\n",
    "        A.HorizontalFlip(p=1.0),    # 水平翻转，当被选择时应用的概率为1.0\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=1.0),  # 随机亮度对比度调整\n",
    "        A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=1.0)  # 色调饱和度调整\n",
    "    ], p=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_da_image(img_name, ID_name):\n",
    "    image_path = images_path / f\"{img_name}.png\" if os.path.exists(images_path / f\"{img_name}.png\") else images_path / f\"{img_name}.tif\"\n",
    "    image = cv2.imread(str(image_path))\n",
    "    if image is not None:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        transformed = transform(image=image)\n",
    "        transformed_image = transformed[\"image\"]\n",
    "\n",
    "        new_img_name = f\"DA_{ID_name}.png\"\n",
    "        new_img_path = da_images_path / new_img_name\n",
    "        cv2.imwrite(str(new_img_path), cv2.cvtColor(transformed_image, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    return new_img_name.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2242"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def LP_ROS(D, size_addition=0.25):\n",
    "    samples_to_add = int(len(D) * size_addition)\n",
    "    \n",
    "    # Group samples according to their labelsets\n",
    "    label_set_bags = {}\n",
    "    for index, sample in D.iterrows():\n",
    "        labelset = tuple(sample[1:])  # Assuming 'labelset' is a column containing the labelset as a tuple or list\n",
    "        if labelset not in label_set_bags:\n",
    "            label_set_bags[labelset] = []\n",
    "        label_set_bags[labelset].append(sample)\n",
    "    \n",
    "    # Calculate the average number of samples per labelset\n",
    "    mean_size = sum(len(bag) for bag in label_set_bags.values()) / len(label_set_bags)\n",
    "    \n",
    "    # Obtain minority labels bags\n",
    "    min_bag = [bag for bag in label_set_bags.values() if len(bag) < mean_size]\n",
    "    \n",
    "    # Calculate mean increment\n",
    "    mean_increment = samples_to_add / len(min_bag)\n",
    "    \n",
    "    # Sort bags from largest to smallest\n",
    "    min_bag.sort(key=len, reverse=True)\n",
    "    \n",
    "    # Augment instances\n",
    "    new_samples = []\n",
    "    ID_name = 1\n",
    "    for bag in min_bag:\n",
    "        increment = min(mean_size - len(bag), mean_increment)\n",
    "        for _ in range(int(increment)):\n",
    "            # Clone random samples from the minority bag\n",
    "            sample_to_clone = random.choice(bag)\n",
    "            new_image_name = get_da_image(sample_to_clone.iloc[0], ID_name)\n",
    "            new_samples.append([new_image_name] + sample_to_clone[1:].tolist())\n",
    "            ID_name += 1\n",
    "    \n",
    "    # Convert new_samples list to DataFrame if needed\n",
    "    if new_samples:\n",
    "        new_samples_df = pd.DataFrame(new_samples, columns=D.columns)\n",
    "        D = pd.concat([D, new_samples_df], ignore_index=True, axis=0)\n",
    "    \n",
    "    return D\n",
    "\n",
    "da_labels_df = LP_ROS(labels_df, size_addition=0.30)\n",
    "len(da_labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_labels_df.to_csv('../data/fundus/MuReD/lpros030_train_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multilabel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
