{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added 294 samples\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(csv_path, image_dir):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    images = []\n",
    "    possible_extensions = ['.tif', '.png']\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        image_path = None\n",
    "        for ext in possible_extensions:\n",
    "            temp_path = os.path.join(image_dir, f\"{row['ID']}{ext}\")\n",
    "            if os.path.exists(temp_path):\n",
    "                image_path = temp_path\n",
    "                break\n",
    "        if image_path is None:\n",
    "            raise FileNotFoundError(f\"No image found for ID {row['ID']} with extensions {possible_extensions}\")\n",
    "        \n",
    "        image = Image.open(image_path)\n",
    "        image = np.array(image)\n",
    "        labels = row.drop('ID').to_numpy()\n",
    "        images.append({'features': image, 'labels': labels, 'ID': row['ID']})\n",
    "    \n",
    "    return images, df.columns[1:]\n",
    "\n",
    "def calculate_ir_lbl(D, label_index):\n",
    "    label_counts = np.sum([instance['labels'] for instance in D], axis=0)\n",
    "    label_count = label_counts[label_index]\n",
    "    max_label_count = np.max(label_counts)\n",
    "    return max_label_count / label_count if label_count != 0 else float('inf')\n",
    "\n",
    "def calculate_scu_mble_ins(instance, ir_lbl):\n",
    "    instance_labels = np.where(instance['labels'] == 1)[0]\n",
    "    k = len(instance_labels)\n",
    "    if k == 0:\n",
    "        return 0\n",
    "    product_ir_lbl = reduce(lambda x, y: x * y, (ir_lbl[label] for label in instance_labels), 1)\n",
    "    mean_ir_lbl = np.mean([ir_lbl[label] for label in instance_labels]) if instance_labels.size > 0 else 1\n",
    "    scumble_ins = 1 - (1 / mean_ir_lbl) * (product_ir_lbl ** (1 / k))\n",
    "    return scumble_ins\n",
    "\n",
    "def calculate_scu_mble(D, ir_lbl):\n",
    "    scumble_ins = [calculate_scu_mble_ins(instance, ir_lbl) for instance in D]\n",
    "    scumble = np.mean(scumble_ins)\n",
    "    return scumble, scumble_ins\n",
    "\n",
    "def remedial(D, labels):\n",
    "    # Calculate imbalance levels\n",
    "    ir_lbl = [calculate_ir_lbl(D, i) for i in range(len(labels))]\n",
    "    ir_mean = np.mean(ir_lbl)\n",
    "    \n",
    "    # Calculate SCUMBLE\n",
    "    scumble, scumble_ins = calculate_scu_mble(D, ir_lbl)\n",
    "    \n",
    "    new_id_counter = 0\n",
    "    new_instances = []\n",
    "    for i in range(len(D)):\n",
    "        if scumble_ins[i] > scumble:\n",
    "            instance = D[i]\n",
    "            clone_instance = copy.deepcopy(instance)\n",
    "            clone_instance['ID'] = f\"DA_{new_id_counter}\"\n",
    "            \n",
    "            # Maintain minority labels\n",
    "            instance['labels'][[label for label in range(len(labels)) if ir_lbl[label] <= ir_mean]] = 0\n",
    "            # Maintain majority labels\n",
    "            clone_instance['labels'][[label for label in range(len(labels)) if ir_lbl[label] > ir_mean]] = 0\n",
    "            \n",
    "            new_instances.append(clone_instance)\n",
    "            new_id_counter += 1\n",
    "    \n",
    "    D.extend(new_instances)\n",
    "    print(f\"added {new_id_counter+1} samples\")\n",
    "    return D\n",
    "\n",
    "csv_path = '../data/fundus/MuReD/train_data.csv'\n",
    "image_dir = '../data/fundus/MuReD/images/images/'\n",
    "dataset, labels = load_dataset(csv_path, image_dir)\n",
    "preprocessed_dataset = remedial(dataset, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID        aria_c_25_1aria_c_7_2aria_c_38_2aria_c_2_8aria...\n",
      "DR                                                      396\n",
      "NORMAL                                                  395\n",
      "MH                                                      135\n",
      "ODC                                                     211\n",
      "TSLN                                                    125\n",
      "ARMD                                                    126\n",
      "DN                                                      130\n",
      "MYA                                                      71\n",
      "BRVO                                                     63\n",
      "ODP                                                      50\n",
      "CRVO                                                     44\n",
      "CNV                                                      48\n",
      "RS                                                       47\n",
      "ODE                                                      46\n",
      "LS                                                       37\n",
      "CSR                                                      29\n",
      "HTR                                                      28\n",
      "ASR                                                      26\n",
      "CRS                                                      24\n",
      "OTHER                                                   209\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "def save_preprocessed_dataset(D, labels, image_dir, output_csv_path):\n",
    "    if not os.path.exists(image_dir):\n",
    "        os.makedirs(image_dir)\n",
    "\n",
    "    label_data = []\n",
    "    image_names = []\n",
    "    for instance in D:\n",
    "        if 'DA_' in instance['ID']:\n",
    "            image_path = os.path.join(image_dir, f\"{instance['ID']}.png\")\n",
    "            image = Image.fromarray(instance['features'])\n",
    "            image.save(image_path)\n",
    "        else:\n",
    "            possible_extensions = ['.tif', '.png']\n",
    "            for ext in possible_extensions:\n",
    "                temp_path = os.path.join(image_dir, f\"{instance['ID']}{ext}\")\n",
    "                if os.path.exists(temp_path):\n",
    "                    image_path = temp_path\n",
    "                    break\n",
    "            \n",
    "        label_data.append(instance['labels'])\n",
    "        image_names.append(instance['ID'])\n",
    "\n",
    "    label_df = pd.DataFrame(label_data, columns=labels)\n",
    "    label_df.insert(0, 'ID', image_names)\n",
    "    label_df.to_csv(os.path.join(output_csv_path, 'remedial_train_data.csv'), index=False)\n",
    "    \n",
    "    counts = label_df.sum(axis=0)\n",
    "    counts.to_dict()\n",
    "    print(counts)\n",
    "\n",
    "\n",
    "output_dir = '../data/fundus/MuReD/images/remedial/'\n",
    "output_csv_path = '../data/fundus/MuReD/'\n",
    "save_preprocessed_dataset(preprocessed_dataset, labels, output_dir, output_csv_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multilabel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
